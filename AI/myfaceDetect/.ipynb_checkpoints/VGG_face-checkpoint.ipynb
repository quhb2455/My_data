{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Flatten, Dense,Dropout, Activation\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = Sequential()\n",
    "pre_model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "pre_model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "pre_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "pre_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "pre_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "pre_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "pre_model.add(ZeroPadding2D((1,1)))\n",
    "pre_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "pre_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "pre_model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "pre_model.add(Dropout(0.5))\n",
    "pre_model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "pre_model.add(Dropout(0.5))\n",
    "pre_model.add(Convolution2D(2622, (1, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dropout object at 0x000001FCCF0A2948>\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_173 (ZeroPadd (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_174 (ZeroPadd (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_175 (ZeroPadd (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_176 (ZeroPadd (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_177 (ZeroPadd (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_208 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_178 (ZeroPadd (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_209 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_179 (ZeroPadd (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_210 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_180 (ZeroPadd (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_211 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_181 (ZeroPadd (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_212 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_182 (ZeroPadd (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_213 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_183 (ZeroPadd (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_214 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_184 (ZeroPadd (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_215 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_185 (ZeroPadd (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_216 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_217 (Conv2D)          (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_218 (Conv2D)          (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_219 (Conv2D)          (None, 1, 1, 2622)        10742334  \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "pre_model.load_weights('vgg_face_weights.h5')\n",
    "pre_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련되는 가중치 수 :  10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_20 (Model)             (None, 56, 56, 256)       1735488   \n",
      "_________________________________________________________________\n",
      "conv2d_240 (Conv2D)          (None, 50, 50, 4096)      51384320  \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 50, 50, 4096)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_241 (Conv2D)          (None, 50, 50, 4096)      16781312  \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 50, 50, 4096)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_242 (Conv2D)          (None, 50, 50, 2622)      10742334  \n",
      "_________________________________________________________________\n",
      "flatten_41 (Flatten)         (None, 6555000)           0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 256)               1678080256\n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,758,723,967\n",
      "Trainable params: 1,756,988,479\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pre_model = Model(pre_model.layers[0].input, pre_model.layers[-6].output)\n",
    "\n",
    "pre_model.trainable = False\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(pre_model)\n",
    "model.add(layers.Conv2D(4096, (7, 7), activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv2D(4096, (1, 1), activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv2D(2622, (1, 1), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(\"훈련되는 가중치 수 : \", len(model.trainable_weights))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sub\\jupyter_workplace\\face_img\\train\n",
      "['1_IMG_1306.JPG', '1_KakaoTalk_20170123_151439371.jpg', '1_KakaoTalk_20170125_233812488.jpg', '1_KakaoTalk_20170125_233814065.jpg', '1_KakaoTalk_20200102_203745806_09.jpg', '1_KakaoTalk_20200103_104501398.jpg', '1_KakaoTalk_20200103_104946014_12.jpg', '1_KakaoTalk_20200103_111549310_06.jpg', '1_KakaoTalk_20200103_112142722_19.jpg', '1_KakaoTalk_20200103_124940397_19.jpg', '1_KakaoTalk_20200103_124940397_27.jpg', '1_KakaoTalk_20200103_124940397_29.jpg', '1_KakaoTalk_20200103_125433617_04.jpg', '1_KakaoTalk_20200103_125433617_22.jpg', '1_KakaoTalk_20200123_203856280_18.jpg', '1_KakaoTalk_20200123_203856280_19.jpg', '1_KakaoTalk_20200123_204124572_01.jpg', '1_KakaoTalk_20200123_204124572_11.jpg', '1_KakaoTalk_20200123_204124572_13.jpg', '1_KakaoTalk_20200123_204124572_14.jpg', '1_KakaoTalk_20200611_064437134.jpg', '1_KakaoTalk_20200611_064437134_01.jpg', '1_KakaoTalk_20200611_064437134_02.jpg', '1_KakaoTalk_20200611_064437134_04.jpg', '1_KakaoTalk_20200611_064437134_05.jpg', '1_KakaoTalk_20200611_064437134_07.jpg', '1_KakaoTalk_20200611_064437134_08.jpg', '1_KakaoTalk_20200611_064437134_10.jpg', '1_KakaoTalk_20200611_064437134_11.jpg', '1_KakaoTalk_20200611_064437134_16.jpg', '1_KakaoTalk_20200611_064437134_17.jpg', '1_KakaoTalk_20200611_064437134_18.jpg', '1_KakaoTalk_20200611_091954819_02.jpg', '1_KakaoTalk_20200611_092031950.jpg', '1_KakaoTalk_20200611_092031950_01.jpg', '1_KakaoTalk_20200611_092237843.jpg', '1_KakaoTalk_20200611_092237843_01.jpg', '1_KakaoTalk_20200611_092237843_02.jpg', '1_KakaoTalk_20200611_092237843_03.jpg', '1_KakaoTalk_20200611_092237843_04.jpg', '1_KakaoTalk_20200611_092237843_08.jpg', '1_KakaoTalk_20200611_092237843_18.jpg', '1_KakaoTalk_20200611_092318745_07.jpg', '1_KakaoTalk_20200611_092722224_15.jpg', '1_KakaoTalk_20200611_092722224_16.jpg', '1_KakaoTalk_20200611_092722224_17.jpg', '1_KakaoTalk_20200611_092722224_22.jpg', '1_KakaoTalk_20200611_092750617.jpg', '1_KakaoTalk_20200611_092750617_01.jpg', '1_KakaoTalk_20200611_092750617_02.jpg', '1_KakaoTalk_20200611_092750617_03.jpg', '1_KakaoTalk_20200611_092750617_18.jpg', '1_KakaoTalk_20200611_100427090_03.jpg', '1_KakaoTalk_20200611_100427090_07.jpg', '1_KakaoTalk_20200611_100438040.jpg', '1_KakaoTalk_20200611_100539890.jpg', '1_KakaoTalk_20200611_100539890_01.jpg', '1_KakaoTalk_20200611_100636786.jpg', '1_KakaoTalk_20200611_100825451_02.jpg', '1_KakaoTalk_20200611_100825451_03.jpg', '1_KakaoTalk_20200611_100825451_07.jpg', '1_KakaoTalk_20200611_100825451_09.jpg', '1_KakaoTalk_20200611_100825451_11.jpg', '1_KakaoTalk_20200611_100825451_13.jpg', '1_KakaoTalk_20200611_100825451_15.jpg', '1_KakaoTalk_20200611_100825451_17.jpg', '1_KakaoTalk_Moim_4UN7RrD1KJqCgKvKKseIUbAGhQ8tvX.jpg', '1_KakaoTalk_Moim_62KGPeIwtx9F8BOFMgXLA5H2mU8lOy.jpg', '2_KakaoTalk_20200102_051813424_16.jpg', '2_KakaoTalk_20200102_051813424_17.jpg', '2_KakaoTalk_20200103_104501398_10.jpg', '2_KakaoTalk_20200103_104946014_11.jpg', '2_KakaoTalk_20200103_111549310_05.jpg', '2_KakaoTalk_20200103_111549310_13.jpg', '2_KakaoTalk_20200103_124940397_28.jpg', '2_KakaoTalk_20200103_125433617_02.jpg', '2_KakaoTalk_20200103_125433617_03.jpg', '2_KakaoTalk_20200103_125433617_19.jpg', '2_KakaoTalk_20200611_064437134_12.jpg', '2_KakaoTalk_20200611_064437134_25.jpg', '2_KakaoTalk_20200611_092031950_02.jpg', '2_KakaoTalk_20200611_092237843_14.jpg', '2_KakaoTalk_20200611_092318745_06.jpg', '2_KakaoTalk_20200611_092722224_05.jpg', '2_KakaoTalk_20200611_092722224_20.jpg', '2_KakaoTalk_20200611_092750617_04.jpg', '2_KakaoTalk_20200611_092750617_05.jpg', '2_KakaoTalk_20200611_092750617_09.jpg', '2_KakaoTalk_20200611_092750617_10.jpg', '2_KakaoTalk_20200611_100427090_04.jpg', '2_KakaoTalk_20200611_100427090_06.jpg', '2_KakaoTalk_20200611_100825451_02.jpg', '2_KakaoTalk_20200611_100825451_04.jpg', '2_KakaoTalk_20200611_100825451_05.jpg', '2_KakaoTalk_20200611_100825451_06.jpg', '2_KakaoTalk_20200611_100825451_08.jpg', '2_KakaoTalk_20200611_100825451_10.jpg', '2_KakaoTalk_20200611_100825451_12.jpg', '2_KakaoTalk_20200611_100825451_16.jpg', '3_KakaoTalk_20200103_111549310_11.jpg', '3_KakaoTalk_20200103_111549310_16.jpg', 'myface']\n"
     ]
    }
   ],
   "source": [
    "import os,sys,shutil\n",
    "\n",
    "base_dir = r'C:\\Users\\Sub\\jupyter_workplace\\face_img'\n",
    "\n",
    "img_path = os.path.join(base_dir,'resize')\n",
    "\n",
    "train_path = os.path.join(base_dir, 'train')\n",
    "if(os.path.isdir(train_path) == False) :\n",
    "    train_path = os.path.join(train_path, 'myface')\n",
    "    os.mkdir(train_path)\n",
    "\n",
    "validation_path = os.path.join(base_dir,'validation')\n",
    "if(os.path.isdir(validation_path) == False) :\n",
    "    validation_path = os.path.join(validation_path, 'myface')\n",
    "    os.mkdir(validation_path)\n",
    "    \n",
    "test_path = os.path.join(base_dir,'test')\n",
    "if(os.path.isdir(test_path) == False) :\n",
    "    test_path = os.path.join(test_path, 'myface')\n",
    "    os.mkdir(test_path)\n",
    "\n",
    "img_lists = os.listdir(img_path)\n",
    "for img_list in img_lists[:101] :\n",
    "    img = os.path.join(img_path,img_list)\n",
    "    shutil.copy(img, train_path)\n",
    "\n",
    "for img_list in img_lists[101:126] :\n",
    "    img = os.path.join(img_path,img_list)\n",
    "    shutil.copy(img, validation_path)\n",
    "\n",
    "for img_list in img_lists[126:] :\n",
    "    img = os.path.join(img_path,img_list)\n",
    "    shutil.copy(img, test_path)\n",
    "print(train_path)\n",
    "print(os.listdir(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101 images belonging to 1 classes.\n",
      "Found 25 images belonging to 1 classes.\n",
      "Found 26 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 2,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 2,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 2,\n",
    "    class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = optimizers.RMSprop(lr = 1e-5),\n",
    "             metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
